1. Redis
a) 
Redis იყენებს სხვადასხვა მონაცემთა სტრუქტურას, რაც მას მოქნილ და ეფექტურ სისტემად აქცევს.

Strings – ერთ-ერთი ყველაზე მარტივი ტიპი, გამოიყენება cache-სთვის, counters-თვის და session management-ისთვის.
Lists – ელემენტების რიგი (queue/stack), რომელიც სასარგებლოა მორიგეობით დამუშავებისთვის.
Sets – უნიკალური ელემენტების კოლექცია, გამოიყენება დუბლიკატების ამოსაცნობად ან follow/like სისტემებისთვის.
Sorted Sets – როგორც Set, მაგრამ თითოეულ ელემენტს აქვს ქულა (score), რაც სასარგებლოა ლიდერბორდების ან რეიტინგების შესაქმნელად.
Hashes – key-value წყვილების კოლექცია, რომელიც განკუთვნილია ობიექტების ეფექტურად შენახვისთვის (მაგ., მომხმარებლის პროფილები).

b) 
Redis იყენებს რამდენიმე მიდგომას მონაცემთა მდგრადობისთვის:
RDB (Redis Database Backup) – პერიოდული snapshot-ების აღება დისკზე.
AOF (Append-Only File) – ყოველი ბრძანების ჩაწერა ლოგში, რაც უზრუნველყოფს მონაცემთა აღდგენას ავარიული გათიშვის შემდეგ.
Hybrid Mode – ორივე მეთოდის კომბინაცია, რომელიც აძლიერებს მდგრადობას და სწრაფ მუშაობას.

--------------------------------------------------------
2. Apache Kafka-ს შესახებ
a) 
Kafka-ს არქიტექტურა რამდენიმე ძირითად ელემენტზეა აგებული:
Broker – დამოუკიდებელი სერვერი, რომელიც მონაცემებს ინახავს და მომხმარებლებს აწვდის.
Topics – მონაცემთა ნაკადების ლოგიკური ჯგუფები, სადაც იწერება შეტყობინებები.
Partitions – თემა დაყოფილია რამდენიმე ნაწილად, რაც საშუალებას აძლევს სხვადასხვა consumer-ს პარალელურად დაამუშაოს მონაცემები.
Consumer Groups – კონსიუმერების ჯგუფი, რომელიც ანაწილებს დატვირთვას და უზრუნველყოფს failover-ს.

b) 
Kafka-ს მასშტაბირება ხდება პარტიციების დამატებით, რაც უზრუნველყოფს პარალელურ დამუშავებას. მაღალ წარმადობას განაპირობებს:
Disk Sequential Writes – მონაცემები ემატება ბოლოში, რაც სწრაფია.
Zero Copy Principle – მონაცემები არ კოპირდება ზედმეტად, არამედ პირდაპირ გადაეცემა network buffers-ს.
Consumer Pull Model – მომხმარებლები თვითონ იწერენ მონაცემებს, რაც თავიდან არიდებს გადატვირთვას.

---------------------------------------------------------

3. Apache Airflow-ს შესახებ
a) 
DAG (Directed Acyclic Graph) წარმოადგენს ამოცანების ქსელს, რომელიც განსაზღვრავს, როგორ უნდა შესრულდეს სამუშაო პროცესები (workflow).

მახასიათებლები:
მიმართულება – ამოცანებს აქვთ დასაწყისი და დასასრული, ციკლების გარეშე.
დამოკიდებულებები – თითოეული task დამოკიდებულია წინამორბედებზე.
მოქნილობა – შესაძლებელია პარამეტრების გამოყენება და workflow-ს ავტომატური გაშვება.
b) 
Operators – აქტიური მოქმედებები, მაგალითად, SQL-ის გაშვება, ფაილის ატვირთვა ან API-სთან კომუნიკაცია.
Sensors – პასიური პროცესები, რომლებიც ელოდებიან რაიმე მოვლენის მოხდენას (მაგალითად, ფაილის ჩაწერას S3-ში).

-----------------------------------------------------------

4. ETL vs ELT
a) 
ETL (Extract, Transform, Load) – მონაცემები ჯერ გარდაიქმნება, შემდეგ იტვირთება საცავში.
ELT (Extract, Load, Transform) – მონაცემები ჯერ იტვირთება საცავში, შემდეგ გარდაიქმნება.
მთავარი განსხვავებები:
ETL მუშაობს სტრუქტურირებულ მონაცემებთან, ELT უკეთესია დიდი მოცულობის არასტრუქტურირებული მონაცემებისთვის.
ETL იყენებს მონაცემთა საწყობს, ELT – Data Lake-ს.

b)
ETL უკეთესია, როცა...
საჭიროა სტანდარტიზაცია და ხარისხის კონტროლი (მაგ., ბანკებში).
ELT უკეთესია, როცა...
გვაქვს დიდი მონაცემები და ძლიერი cloud warehouse (მაგ., BigQuery, Snowflake).

-----------------------------------------------------------------

5. **მონაცემთა შენახვის კონცეფციები**

a) 
Data Lake – მონაცემთა საცავი, რომელიც ინახავს ნედლ მონაცემებს (raw data) სხვადასხვა ფორმატში (სტრუქტურირებული, ნახევრად-სტრუქტურირებული, არასტრუქტურირებული). მისი გამოყენება ხშირია Machine Learning-სა და Big Data-ში, მაგრამ მონაცემები ხშირად მოუწესრიგებელია.
Data Warehouse – მონაცემთა სტრუქტურირებული საცავი, სადაც ინფორმაცია გაწმენდილი და დამუშავებულია. ძირითადად გამოიყენება ბიზნეს ანალიტიკაში (BI) და ანგარიშგებაში.
Data Mart – მონაცემთა საცავის ნაწილი, რომელიც ფოკუსირებულია კონკრეტულ თემატიკაზე ან ბიზნეს განყოფილებაზე. მისი მიზანი არის სპეციფიკური მომხმარებლებისთვის ოპტიმიზირებული მონაცემების მიწოდება.
b) 
Data Lake ძირითადად მუშაობს ELT პრინციპით – მონაცემები ჯერ ინახება და შემდეგ გარდაიქმნება საჭიროებისამებრ.
Data Warehouse იყენებს ETL მეთოდს – მონაცემები ჯერ მუშავდება, შემდეგ იტვირთება.
Data Mart ხშირად არის Data Warehouse-ის ნაწილია, რომელიც კონცენტრირებულია კონკრეტულ სექტორზე (მაგალითად, ფინანსები, გაყიდვები, მარკეტინგი).


